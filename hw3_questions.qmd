---
title: "Multinomial Logit Model"
author: "Savitha Murali"
date: today
format: 
  html:
    code-fold: true
    df-print: kable
    theme: cosmo
    highlight: tango
editor: visual
---

This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm. 

## 1. Likelihood for the Multi-nomial Logit (MNL) Model

Suppose we have $i=1,\ldots,n$ consumers who each select exactly one product $j$ from a set of $J$ products. The outcome variable is the identity of the product chosen $y_i \in \{1, \ldots, J\}$ or equivalently a vector of $J-1$ zeros and $1$ one, where the $1$ indicates the selected product. For example, if the third product was chosen out of 3 products, then either $y=3$ or $y=(0,0,1)$ depending on how we want to represent it. Suppose also that we have a vector of data on each product $x_j$ (eg, brand, price, etc.). 

We model the consumer's decision as the selection of the product that provides the most utility, and we'll specify the utility function as a linear function of the product characteristics:

$$ U_{ij} = x_j'\beta + \epsilon_{ij} $$

where $\epsilon_{ij}$ is an i.i.d. extreme value error term. 

The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer $i$ chooses product $j$:

$$ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} $$

For example, if there are 3 products, the probability that consumer $i$ chooses product 3 is:

$$ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta}} $$

A clever way to write the individual likelihood function for consumer $i$ is the product of the $J$ probabilities, each raised to the power of an indicator variable ($\delta_{ij}$) that indicates the chosen product:

$$ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}$$

Notice that if the consumer selected product $j=3$, then $\delta_{i3}=1$ while $\delta_{i1}=\delta_{i2}=0$ and the likelihood is:

$$ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^3e^{x_k'\beta}} $$

The joint likelihood (across all consumers) is the product of the $n$ individual likelihoods:

$$ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} $$

And the joint log-likelihood function is:

$$ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) $$


## 2. Simulate Conjoint Data

We will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a "no choice" option; each simulated respondent must select one of the 3 alternatives. 

Each alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from \$4 to \$32 in increments of \$4.

The part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer $i$ for hypothethical streaming service $j$ is 

$$
u_{ij} = (1 \times Netflix_j) + (0.5 \times Prime_j) + (-0.8*Ads_j) - 0.1\times Price_j + \varepsilon_{ij}
$$

where the variables are binary indicators and $\varepsilon$ is Type 1 Extreme Value (ie, Gumble) distributed.

The following code provides the simulation of the conjoint data.

:::: {.callout-note collapse="true"}
```{r}
# set seed for reproducibility
set.seed(123)

# define attributes
brand <- c("N", "P", "H") # Netflix, Prime, Hulu
ad <- c("Yes", "No")
price <- seq(8, 32, by=4)

# generate all possible profiles
profiles <- expand.grid(
    brand = brand,
    ad = ad,
    price = price
)
m <- nrow(profiles)

# assign part-worth utilities (true parameters)
b_util <- c(N = 1.0, P = 0.5, H = 0)
a_util <- c(Yes = -0.8, No = 0.0)
p_util <- function(p) -0.1 * p

n_peeps <- 100
n_tasks <- 10
n_alts <- 3

# function to simulate one respondent’s data
sim_one <- function(id) {
  
    datlist <- list()
    
    # loop over choice tasks
    for (t in 1:n_tasks) {
        
        # randomly sample 3 alts (better practice would be to use a design)
        dat <- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])
        
        # compute deterministic portion of utility
        dat$v <- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |> round(10)
        
        # add Gumbel noise (Type I extreme value)
        dat$e <- -log(-log(runif(n_alts)))
        dat$u <- dat$v + dat$e
        
        # identify chosen alternative
        dat$choice <- as.integer(dat$u == max(dat$u))
        
        # store task
        datlist[[t]] <- dat
    }
    
    # combine all tasks for one respondent
    do.call(rbind, datlist)
}

conjoint_data <- do.call(rbind, lapply(1:n_peeps, sim_one))

conjoint_data <- conjoint_data[ , c("resp", "task", "brand", "ad", "price", "choice")]

rm(list=setdiff(ls(), "conjoint_data"))
```
::::

## 3. Preparing the Data for Estimation

The "hard part" of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer $i$, covariate $k$, and product $j$) instead of the typical 2 dimensions for cross-sectional regression models (consumer $i$ and covariate $k$). The fact that each task for each respondent has the same number of alternatives (3) helps.  In addition, we need to convert the categorical variables for brand and ads into binary variables.

:::: {.callout-note collapse="true"}
```{r}
# Load necessary package
# install.packages("dplyr") # Run this once if not already installed
library(dplyr)

# Load the dataset
df <- read.csv("conjoint_data.csv")

# Create a unique identifier for each choice situation (respondent-task combination)
df$resp_task <- paste(df$resp, df$task, sep = "_")

# One-hot encode categorical variables: brand and ad
# Reference levels: brand H, ad No
df$brand_N <- ifelse(df$brand == "N", 1, 0)
df$brand_P <- ifelse(df$brand == "P", 1, 0)
df$ad_Yes  <- ifelse(df$ad == "Yes", 1, 0)

# Sort the data for clean indexing
df <- df %>% arrange(resp, task)

# Create an alternative ID for each profile within a task
df <- df %>%
  group_by(resp, task) %>%
  mutate(alt_id = row_number() - 1) %>%
  ungroup()

# View the reshaped data
head(df)
```
::::

## 4. Estimation via Maximum Likelihood
:::: {.callout-note collapse="true"}
```{r}
# Load required packages
library(dplyr)

# Load and prepare data
df <- read.csv("conjoint_data.csv")

# Create a unique identifier for each choice task
df$resp_task <- paste(df$res, df$task, sep = "_")

# Convert categorical variables to dummy variables (reference: brand H, ad No)
df <- df %>%
  mutate(
    brand_N = ifelse(brand == "N", 1, 0),
    brand_P = ifelse(brand == "P", 1, 0),
    ad_Yes  = ifelse(ad == "Yes", 1, 0)
  ) %>%
  arrange(resp, task)

# Create X matrix and choice vector y
X <- as.matrix(df[, c("brand_N", "brand_P", "ad_Yes", "price")])
y <- df$choice
group_sizes <- table(df$resp_task)

# Define negative log-likelihood function
neg_log_likelihood <- function(beta) {
  utilities <- X %*% beta
  start <- 1
  loglik <- 0
  for (size in group_sizes) {
    end <- start + size - 1
    u_task <- utilities[start:end]
    y_task <- y[start:end]
    exp_u <- exp(u_task - max(u_task))  # numerical stability
    prob <- exp_u / sum(exp_u)
    chosen_prob <- prob[which(y_task == 1)]
    loglik <- loglik + log(chosen_prob)
    start <- end + 1
  }
  return(-loglik)
}
# Estimate MLE
init_beta <- rep(0, 4)
result <- optim(
  par = init_beta,
  fn = neg_log_likelihood,
  method = "BFGS",
  hessian = TRUE
)
# Extract estimates
beta_hat <- result$par
hessian <- result$hessian
se <- sqrt(diag(solve(hessian)))
z <- 1.96
ci_lower <- beta_hat - z * se
ci_upper <- beta_hat + z * se
# Summarize results
param_names <- c("β_netflix", "β_prime", "β_ads", "β_price")
summary_df <- data.frame(
  Parameter = param_names,
  Estimate = beta_hat,
  Std.Error = se,
  CI_Lower = ci_lower,
  CI_Upper = ci_upper
)
print(summary_df)
```
::::

## 5. Estimation via Bayesian Methods
:::: {.callout-note collapse="true"}
```{r}
# Load data
df <- read.csv("conjoint_data.csv")
# Create a choice set ID
df$resp_task <- paste(df$resp, df$task, sep = "_")
# Convert categorical variables to dummies (reference: brand H, ad No)
df$brand_N <- ifelse(df$brand == "N", 1, 0)
df$brand_P <- ifelse(df$brand == "P", 1, 0)
df$ad_Yes  <- ifelse(df$ad == "Yes", 1, 0)
# Build X matrix
X <- as.matrix(df[, c("brand_N", "brand_P", "ad_Yes", "price")])
y <- df$choice
group_sizes <- table(df$resp_task)
# Log-likelihood function
log_likelihood <- function(beta) {
  utilities <- X %*% beta
  start <- 1
  loglik <- 0
  for (size in group_sizes) {
    end <- start + size - 1
    u_task <- utilities[start:end]
    y_task <- y[start:end]
    exp_u <- exp(u_task - max(u_task))  # stability
    probs <- exp_u / sum(exp_u)
    chosen_prob <- probs[y_task == 1]
    loglik <- loglik + log(chosen_prob)
    start <- end + 1
  }
  return(loglik)
}
# Log-prior function
log_prior <- function(beta) {
  dnorm(beta[1], 0, sqrt(5), log = TRUE) +
    dnorm(beta[2], 0, sqrt(5), log = TRUE) +
    dnorm(beta[3], 0, sqrt(5), log = TRUE) +
    dnorm(beta[4], 0, 1, log = TRUE)
}
# Log-posterior function
log_posterior <- function(beta) {
  log_likelihood(beta) + log_prior(beta)
}
# MCMC settings
n_iter <- 11000
burn_in <- 1000
samples <- matrix(NA, nrow = n_iter, ncol = 4)
colnames(samples) <- c("beta_netflix", "beta_prime", "beta_ads", "beta_price")

# Proposal standard deviations
proposal_sd <- c(0.05, 0.05, 0.05, 0.005)
# Initialize
set.seed(123)
beta_curr <- rep(0, 4)
log_post_curr <- log_posterior(beta_curr)
accept <- 0

# MCMC loop
for (i in 1:n_iter) {
  beta_prop <- beta_curr + rnorm(4, 0, proposal_sd)
  log_post_prop <- log_posterior(beta_prop)
  alpha <- exp(log_post_prop - log_post_curr)
  if (runif(1) < alpha) {
    beta_curr <- beta_prop
    log_post_curr <- log_post_prop
    accept <- accept + 1
  }
  samples[i, ] <- beta_curr
}

accept_rate <- accept / n_iter
cat("Acceptance Rate:", round(accept_rate, 3), "\n")

# Drop burn-in
posterior <- samples[(burn_in + 1):n_iter, ]

# Summary
posterior_summary <- apply(posterior, 2, function(x) {
  c(mean = mean(x), sd = sd(x),
    lower = quantile(x, 0.025),
    upper = quantile(x, 0.975))
})
posterior_summary <- as.data.frame(t(posterior_summary))
posterior_summary
```
::::

:::: {.callout-note collapse="true"}
```{r}
par(mfrow = c(1, 2))

# Trace plot
plot(posterior[, 4], type = "l", col = "darkblue",
     main = "Trace Plot: β_price",
     xlab = "Iteration", ylab = "Value")

# Histogram of posterior distribution
hist(posterior[, 4], breaks = 30, col = "lightblue", probability = TRUE,
     main = "Posterior Distribution: β_price",
     xlab = "Value", ylab = "Density")
abline(v = mean(posterior[, 4]), col = "red", lwd = 2)
```
::::

:::: {.callout-note collapse="true"}
```{r}
# Clean up posterior_summary from apply()
posterior_summary <- as.data.frame(t(posterior_summary))
posterior_summary <- posterior_summary[1:4, ]  # Only keep 4 rows

# Add labels and structure
posterior_summary$Method <- "Bayesian"
posterior_summary$Parameter <- c("β_netflix", "β_prime", "β_ads", "β_price")

# Rename columns to match MLE summary
colnames(posterior_summary)[1:4] <- c("Estimate", "Std.Error", "CI_Lower", "CI_Upper")
posterior_summary <- posterior_summary[, c("Parameter", "Estimate", "Std.Error", "CI_Lower", "CI_Upper", "Method")]

# Ensure MLE summary matches format
summary_df$Method <- "MLE"
summary_df <- summary_df[, c("Parameter", "Estimate", "Std.Error", "CI_Lower", "CI_Upper", "Method")]

# Combine both tables
combined_results <- rbind(summary_df, posterior_summary)

# Display as a nice table
knitr::kable(combined_results, digits = 4, caption = "Comparison of MLE and Bayesian Estimates")
```
::::

## 6. Discussion
Suppose we did not simulate the data and were analyzing results as if they came from a real-world survey. Here’s what we would observe from the parameter estimates:

- **$\beta_\text{Netflix} > \beta_\text{Prime}$**: This suggests that consumers, on average, **prefer Netflix to Prime Video**, holding ad presence and price constant. A higher coefficient for Netflix implies it provides higher utility or satisfaction relative to other brands.

- **$\beta_\text{Prime} > 0$**: While Netflix is preferred the most, the positive coefficient for Prime still indicates that it's also more appealing than the baseline brand (Hulu). In practice, this aligns with brand equity and customer perception data for these platforms.

- **$\beta_\text{price} < 0$**: This is consistent with economic theory and intuition — as price increases, the likelihood of a product being chosen **decreases**. The negative coefficient confirms that consumers are **price sensitive**.

- **Posterior vs MLE Results**: Both methods yield very similar estimates, which is expected due to the **relatively weak priors** and sufficient data volume. This confirms the robustness of the MLE results and shows how Bayesian methods can reinforce frequentist inference.

In summary, the parameter estimates are sensible, interpretable, and align with expected consumer behavior. Even without knowing the underlying data was simulated, the model provides valuable insights into preferences for brand, price sensitivity, and advertising tolerance in streaming service choices.

### Extension to Hierarchical (Multilevel) Models
To move from a basic Multinomial Logit (MNL) model to a **hierarchical** or **random-parameters** logit model — which is more common in real-world conjoint analysis — the key idea is to allow **individual-level heterogeneity** in preferences.

#### Conceptual Change
In the standard MNL model, we assume:
$$
\beta_i = \beta \quad \text{(same for all individuals)}
$$

In a **hierarchical model**, we instead assume:
$$
\beta_i \sim \mathcal{N}(\mu, \Sigma)
$$

Each respondent \( i \) has their own set of parameters \( \beta_i \), drawn from a population-level distribution with mean \( \mu \) and covariance \( \Sigma \).

#### Simulation Changes
To simulate data from a hierarchical model:
- Draw a different \( \beta_i \) for each respondent from a common prior (e.g., multivariate normal)
- Use these individual \( \beta_i \)s to compute utility and choices across tasks
- Store and analyze the data accordingly

#### Estimation Changes

To estimate a hierarchical model:
- Use **Bayesian methods** such as **Hierarchical Bayes (HB)** via MCMC, or **frequentist mixed logit** (e.g., using `mlogit` or `bayesm` in R)
- You'll now estimate:
  - The mean vector \( \mu \) of the population
  - The covariance matrix \( \Sigma \) (to capture variation in preferences)
  - And each individual's \( \beta_i \)

####  Why This Matters
- Real-world consumers do not all have the same preferences.
- Hierarchical models better capture **preference heterogeneity**.
- This leads to **more accurate predictions**, better **market segmentation**, and more **realistic simulations** of behavior.









