[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Savitha Murali",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "Untitled-1.html",
    "href": "Untitled-1.html",
    "title": "Savitha's website",
    "section": "",
    "text": "import pandas as pd\n\n\ndta_file = 'karlan_list_2007.dta'\ncsv_file = 'karlan_list_2007.csv'\n\n# Read the .dta file\ndf = pd.read_stata(dta_file)\n\n\n# Convert and save to .csv\ndf.to_csv(csv_file, index=False)\n\ndf.shape\n\n(50083, 51)\n\n\n\ndf = pd.read_csv(csv_file)\ndf.columns = df.columns.str.strip().str.lower()\ndataset_description = df.describe(include='all').transpose()\ndataset_description['missing_values'] = df.isnull().sum()\ndataset_description['data_type'] = df.dtypes\ndescription_subset = dataset_description[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'missing_values', 'data_type']]\ndescription_subset\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\nmissing_values\ndata_type\n\n\n\n\ntreatment\n50083.0\n0.666813\n0.471357\n0.0\n0.0\n1.0\n1.0\n1.0\n0\nint64\n\n\ncontrol\n50083.0\n0.333187\n0.471357\n0.0\n0.0\n0.0\n1.0\n1.0\n0\nint64\n\n\nratio\n50083\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0\nobject\n\n\nratio2\n50083.0\n0.222311\n0.415803\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nratio3\n50083.0\n0.222211\n0.415736\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nsize\n50083\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0\nobject\n\n\nsize25\n50083.0\n0.166723\n0.372732\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nsize50\n50083.0\n0.166623\n0.372643\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nsize100\n50083.0\n0.166723\n0.372732\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nsizeno\n50083.0\n0.166743\n0.37275\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nask\n50083\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0\nobject\n\n\naskd1\n50083.0\n0.222311\n0.415803\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\naskd2\n50083.0\n0.222291\n0.41579\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\naskd3\n50083.0\n0.222211\n0.415736\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nask1\n50083.0\n71.501807\n101.728936\n25.0\n35.0\n45.0\n65.0\n1500.0\n0\nint64\n\n\nask2\n50083.0\n91.792724\n127.252628\n35.0\n45.0\n60.0\n85.0\n1875.0\n0\nint64\n\n\nask3\n50083.0\n111.046263\n151.673562\n50.0\n55.0\n70.0\n100.0\n2250.0\n0\nint64\n\n\namount\n50083.0\n0.915694\n8.709199\n0.0\n0.0\n0.0\n0.0\n400.0\n0\nfloat64\n\n\ngave\n50083.0\n0.020646\n0.142197\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\namountchange\n50083.0\n-52.672016\n1267.238643\n-200412.12\n-50.0\n-30.0\n-25.0\n275.0\n0\nfloat64\n\n\nhpa\n50083.0\n59.384977\n71.17731\n0.0\n30.0\n45.0\n60.0\n1000.0\n0\nfloat64\n\n\nltmedmra\n50083.0\n0.49372\n0.499966\n0.0\n0.0\n0.0\n1.0\n1.0\n0\nint64\n\n\nfreq\n50083.0\n8.039355\n11.394454\n0.0\n2.0\n4.0\n10.0\n218.0\n0\nint64\n\n\nyears\n50082.0\n6.09754\n5.503492\n0.0\n2.0\n5.0\n9.0\n95.0\n1\nfloat64\n\n\nyear5\n50083.0\n0.508815\n0.499927\n0.0\n0.0\n1.0\n1.0\n1.0\n0\nint64\n\n\nmrm2\n50082.0\n13.007268\n12.081403\n0.0\n4.0\n8.0\n19.0\n168.0\n1\nfloat64\n\n\ndormant\n50083.0\n0.523471\n0.499454\n0.0\n0.0\n1.0\n1.0\n1.0\n0\nint64\n\n\nfemale\n48972.0\n0.277669\n0.447854\n0.0\n0.0\n0.0\n1.0\n1.0\n1111\nfloat64\n\n\ncouple\n48935.0\n0.091897\n0.288884\n0.0\n0.0\n0.0\n0.0\n1.0\n1148\nfloat64\n\n\nstate50one\n50083.0\n0.000998\n0.031581\n0.0\n0.0\n0.0\n0.0\n1.0\n0\nint64\n\n\nnonlit\n49631.0\n2.473918\n1.961528\n0.0\n1.0\n3.0\n4.0\n6.0\n452\nfloat64\n\n\ncases\n49631.0\n1.499768\n1.15514\n0.0\n1.0\n1.0\n2.0\n4.0\n452\nfloat64\n\n\nstatecnt\n50083.0\n5.99882\n5.746324\n0.001995\n1.833234\n3.538799\n9.607021\n17.368841\n0\nfloat64\n\n\nstateresponse\n50083.0\n0.020627\n0.005171\n0.0\n0.018163\n0.01971\n0.023048\n0.076923\n0\nfloat64\n\n\nstateresponset\n50083.0\n0.021989\n0.006257\n0.0\n0.018493\n0.021697\n0.024703\n0.111111\n0\nfloat64\n\n\nstateresponsec\n50080.0\n0.017717\n0.007516\n0.0\n0.012862\n0.019881\n0.020806\n0.052632\n3\nfloat64\n\n\nstateresponsetminc\n50080.0\n0.004273\n0.009112\n-0.047619\n-0.001388\n0.001779\n0.010545\n0.111111\n3\nfloat64\n\n\nperbush\n50048.0\n0.48794\n0.078735\n0.090909\n0.444444\n0.484849\n0.525253\n0.731959\n35\nfloat64\n\n\nclose25\n50048.0\n0.185702\n0.38887\n0.0\n0.0\n0.0\n0.0\n1.0\n35\nfloat64\n\n\nred0\n50048.0\n0.404452\n0.490791\n0.0\n0.0\n0.0\n1.0\n1.0\n35\nfloat64\n\n\nblue0\n50048.0\n0.595548\n0.490791\n0.0\n0.0\n1.0\n1.0\n1.0\n35\nfloat64\n\n\nredcty\n49978.0\n0.510245\n0.4999\n0.0\n0.0\n1.0\n1.0\n1.0\n105\nfloat64\n\n\nbluecty\n49978.0\n0.488715\n0.499878\n0.0\n0.0\n0.0\n1.0\n1.0\n105\nfloat64\n\n\npwhite\n48217.0\n0.819599\n0.168561\n0.009418\n0.755845\n0.872797\n0.938827\n1.0\n1866\nfloat64\n\n\npblack\n48047.0\n0.08671\n0.135868\n0.0\n0.014729\n0.036554\n0.090882\n0.989622\n2036\nfloat64\n\n\npage18_39\n48217.0\n0.321694\n0.103039\n0.0\n0.258311\n0.305534\n0.369132\n0.997544\n1866\nfloat64\n\n\nave_hh_sz\n48221.0\n2.429012\n0.378115\n0.0\n2.21\n2.44\n2.66\n5.27\n1862\nfloat64\n\n\nmedian_hhincome\n48209.0\n54815.700533\n22027.316665\n5000.0\n39181.0\n50673.0\n66005.0\n200001.0\n1874\nfloat64\n\n\npowner\n48214.0\n0.669418\n0.193405\n0.0\n0.560222\n0.712296\n0.816798\n1.0\n1869\nfloat64\n\n\npsch_atlstba\n48215.0\n0.391661\n0.186599\n0.0\n0.235647\n0.373744\n0.530036\n1.0\n1868\nfloat64\n\n\npop_propurban\n48217.0\n0.871968\n0.258654\n0.0\n0.884929\n1.0\n1.0\n1.0\n1866\nfloat64\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\nvars_to_test = ['mrm2', 'freq', 'couple', 'median_hhincome']\ndf_clean = df[['treatment'] + vars_to_test].dropna()\ndf_clean.shape\n\n\n(47114, 5)\n\n\n\nt_test_results = []\nregression_results = []\n\nfor var in vars_to_test:\n    # Separate groups\n    treat_group = df_clean[df_clean['treatment'] == 1][var]\n    control_group = df_clean[df_clean['treatment'] == 0][var]\n    # T-test\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n   \n    # Linear regression\n    formula = f\"{var} ~ treatment\"\n    model = smf.ols(formula, data=df_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    t_test_results.append({\n        \"Variable\": var,\n        \"T-test(p-value)\": round(t_pval, 4),\n        \"Significant (T-test)\": \"Yes\" if t_pval &lt; 0.05 else \"No\"\n    })\n\n    regression_results.append({\n        \"Variable\": var,\n        \"Coef\": round(coef, 4),\n        \"Regression(p-value)\": round(reg_pval, 4),\n        \"Significant (Reg)\": \"Yes\" if reg_pval &lt; 0.05 else \"No\"\n    })\n\n\nt_df = pd.DataFrame(t_test_results)\nr_df = pd.DataFrame(regression_results)\n\nprint(\"=== T-Test Results ===\")\nprint(t_df.to_string(index=False))\nprint(\"\\n=== Linear Regression Results ===\")\nprint(r_df.to_string(index=False))\n\n=== T-Test Results ===\n       Variable  T-test(p-value) Significant (T-test)\n           mrm2           0.9372                   No\n           freq           0.9066                   No\n         couple           0.9336                   No\nmedian_hhincome           0.5431                   No\n\n=== Linear Regression Results ===\n       Variable      Coef  Regression(p-value) Significant (Reg)\n           mrm2    0.0093               0.9373                No\n           freq   -0.0132               0.9064                No\n         couple   -0.0002               0.9336                No\nmedian_hhincome -130.5570               0.5438                No"
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale natural field experiment to evaluate how different fundraising strategies influence charitable giving. In partnership with a U.S.-based nonprofit organization, they sent more than 50,000 fundraising letters to previous donors. Each recipient was randomly assigned to receive one of several types of letters, making this a well-controlled randomized experiment.\nThe letters were divided into the following groups:\n\nControl group: Received a standard fundraising appeal with no mention of a matching donation.\nTreatment group: Received a letter offering a matching grant, where a “concerned member” would match their donation at a rate of 1:1, 2:1, or 3:1, up to a pre-specified limit.\n\nWithin the treatment group, two additional features were randomized: - The maximum size of the match (e.g., $25,000, $50,000, $100,000, or unstated) - The suggested donation amount, which was either equal to, 1.25x, or 1.5x the individual’s previous highest contribution\nThis design allowed the authors to answer several behavioral questions, including:\n\nDoes offering a match increase the likelihood of donating?\nDoes a higher match ratio (2:1 or 3:1) further increase donations compared to a 1:1 match?\nDo match size limits or suggested donation amounts influence behavior?\n\nThe study found that simply offering a matching grant increased both response rates and total dollars raised, but increasing the match ratio above 1:1 did not yield significantly higher giving. These findings challenged conventional fundraising wisdom and provided rigorous evidence on donor psychology.\nThis project seeks to replicate the results of Karlan and List’s experiment using the publicly available dataset, and to provide visual and statistical summaries of the key findings.\nThe article and supporting data are available from the AEA website and from Innovations for Poverty Action on Harvard’s Dataverse."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale natural field experiment to evaluate how different fundraising strategies influence charitable giving. In partnership with a U.S.-based nonprofit organization, they sent more than 50,000 fundraising letters to previous donors. Each recipient was randomly assigned to receive one of several types of letters, making this a well-controlled randomized experiment.\nThe letters were divided into the following groups:\n\nControl group: Received a standard fundraising appeal with no mention of a matching donation.\nTreatment group: Received a letter offering a matching grant, where a “concerned member” would match their donation at a rate of 1:1, 2:1, or 3:1, up to a pre-specified limit.\n\nWithin the treatment group, two additional features were randomized: - The maximum size of the match (e.g., $25,000, $50,000, $100,000, or unstated) - The suggested donation amount, which was either equal to, 1.25x, or 1.5x the individual’s previous highest contribution\nThis design allowed the authors to answer several behavioral questions, including:\n\nDoes offering a match increase the likelihood of donating?\nDoes a higher match ratio (2:1 or 3:1) further increase donations compared to a 1:1 match?\nDo match size limits or suggested donation amounts influence behavior?\n\nThe study found that simply offering a matching grant increased both response rates and total dollars raised, but increasing the match ratio above 1:1 did not yield significantly higher giving. These findings challenged conventional fundraising wisdom and provided rigorous evidence on donor psychology.\nThis project seeks to replicate the results of Karlan and List’s experiment using the publicly available dataset, and to provide visual and statistical summaries of the key findings.\nThe article and supporting data are available from the AEA website and from Innovations for Poverty Action on Harvard’s Dataverse."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset comprises 50,083 observations collected from a large-scale field experiment conducted by Karlan and List (2007) to study the effect of matching grants on charitable giving. Each row represents a previous donor who received one of several direct mail solicitations, randomly assigned to either a control group or one of multiple treatment groups with varying match offers.\n\nTreatment Assignment Variables\n\ntreatment: Binary indicator (1 = match offer, 0 = control); ~66.7% of the sample received a match offer\nratio2, ratio3: Indicators for $2:$1 and $3:$1 match offers (1:1 is the reference group)\nsize25, size50, size100, sizeno: Indicators for different match cap thresholds ($25k, $50k, $100k, or unspecified)\n\n\n\nBehavioral Outcomes\n\ngave: Binary indicator of whether a donation was made\namount: Dollar amount donated\namountchange: Change in donation amount from previous gift\n\n\n\nHistorical Donor Characteristics\n\nhpa: Highest previous amount donated\nfreq: Number of prior donations\nyears: Years since first donation\nmrm2: Months since last donation\n\n\n\nDemographic and Contextual Data\n\nfemale, couple: Gender and household indicators (with ~2% missing data)\npwhite, pblack: Proportions of white and Black population in donor’s ZIP code\nmedian_hhincome: Median household income in donor’s ZIP code\npop_propurban: Proportion of population living in urban areas\n\nMost variables are clean and complete. A few (e.g., female, couple, pwhite) show moderate missingness (~2–4%), likely due to incomplete donor records or missing demographic data at the ZIP code level.\nOverall, the dataset is well-structured for causal inference and rich in both treatment metadata and behavioral outcomes, making it ideal for analyzing the effectiveness of charitable fundraising strategies.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.We applied Welch’s t-tests and simple linear regressions to compare:\n\nmrm2: Months since last donation\nfreq: Number of prior donations\nCouple: Couple\nmedian_hhincome: Median household income in donor’s zip code\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\ndta_file = 'karlan_list_2007.dta'\ncsv_file = 'karlan_list_2007.csv'\n# Read the .dta file\ndf = pd.read_stata(dta_file)\n# Convert and save to .csv\ndf.to_csv(csv_file, index=False)\ndf.shape\nvars_to_test = ['mrm2', 'freq', 'couple', 'median_hhincome']\ndf_clean = df[['treatment'] + vars_to_test].dropna()\ndf_clean.shape\nt_test_results = []\nregression_results = []\n\nfor var in vars_to_test:\n    # Separate groups\n    treat_group = df_clean[df_clean['treatment'] == 1][var]\n    control_group = df_clean[df_clean['treatment'] == 0][var]\n    # T-test\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n   \n    # Linear regression\n    formula = f\"{var} ~ treatment\"\n    model = smf.ols(formula, data=df_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    t_test_results.append({\n        \"Variable\": var,\n        \"T-test(p-value)\": round(t_pval, 4),\n        \"Significant (T-test)\": \"Yes\" if t_pval &lt; 0.05 else \"No\"\n    })\n\n    regression_results.append({\n        \"Variable\": var,\n        \"Coef\": round(coef, 4),\n        \"Regression(p-value)\": round(reg_pval, 4),\n        \"Significant (Reg)\": \"Yes\" if reg_pval &lt; 0.05 else \"No\"\n    })\n\n\nt_df = pd.DataFrame(t_test_results)\nr_df = pd.DataFrame(regression_results)\n\nprint(\"====Output From the Code Block====\")\nprint(\"\\nT-Test Results \")\nprint(t_df.to_string(index=False))\nprint(\"\\nLinear Regression Results \")\nprint(r_df.to_string(index=False))\n\n\n====Output From the Code Block====\n\nT-Test Results \n       Variable  T-test(p-value) Significant (T-test)\n           mrm2           0.9372                   No\n           freq           0.9066                   No\n         couple           0.9336                   No\nmedian_hhincome           0.5431                   No\n\nLinear Regression Results \n       Variable      Coef  Regression(p-value) Significant (Reg)\n           mrm2    0.0093               0.9373                No\n           freq   -0.0132               0.9064                No\n         couple   -0.0002               0.9336                No\nmedian_hhincome -130.5570               0.5438                No\n\n\n\n\n\n\nObservation\nAcross all tested variables, we found no statistically significant differences at the 95% confidence Interval. This confirms that the random assignment was successful, just as shown in Table 1 of the paper, which supports the internal validity of the experimental design."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem. Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. Further suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulation setup\nnp.random.seed(42)\ncontrol_p = 0.018\ntreatment_p = 0.022\nn_draws = 10000\n\n# Simulate binary outcomes\ncontrol_draws = np.random.binomial(1, control_p, size=n_draws)\ntreatment_draws = np.random.binomial(1, treatment_p, size=n_draws)\n\n# Calculate sample differences\ndifferences = treatment_draws - control_draws\ncumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\nplt.figure(figsize=(8,4))\nplt.plot(cumulative_avg, label='Cumulative Avg Difference', color='blue')\nplt.axhline(0.004, color='red', linestyle='--', label='True ATE = 0.004')\nplt.xlabel('Number of Simulated Samples')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Law of Large Numbers: Convergence to True Treatment Effect')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nThis plot shows the cumulative average of 10,000 differences between randomly drawn treatment and control responses. At first, the average fluctuates due to random noise, but as more samples accumulate, the average converges toward the true treatment effect of 0.004.\nThis is a demonstration of the Law of Large Numbers (LLN) — as sample size increases, the sample average tends to stabilize and approximate the expected value (true difference in means).\n\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed\nnp.random.seed(42)\n\n# True probabilities\np_control = 0.018\np_treat = 0.022\ntrue_diff = p_treat - p_control\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\n# Set up 2x2 subplot grid\nfig, axes = plt.subplots(4, 1, figsize=(8, 10))\n# Flatten axes array for easier iteration\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    # Store average differences for each simulation\n    avg_diffs = []\n\n    for _ in range(num_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treat, n)\n        avg_diffs.append(np.mean(treatment) - np.mean(control))\n    # Plot histogram\n    axes[i].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='black', linestyle='--', label='Zero')\n    axes[i].axvline(true_diff, color='red', linestyle='--', label='True Diff = 0.004')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Average Treatment Effect\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nThese histograms show the sampling distribution of the difference in donation rates between treatment and control groups at different sample sizes. Each histogram is based on 1,000 simulated experiments. - At small sample sizes (e.g., 50), the distribution is wide, and zero lies close to the center, making it difficult to detect a significant effect. - As the sample size increases to 200, 500, and 1000, the distribution becomes narrower and more centered around the true effect (0.004). - By sample size 1000, zero is clearly in the tails of the distribution, showing that larger samples provide more statistical power to detect small effects."
  },
  {
    "objectID": "hw1_questions.html#effect-of-matching-donations-on-response-rate",
    "href": "hw1_questions.html#effect-of-matching-donations-on-response-rate",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Effect of Matching Donations on Response Rate",
    "text": "Effect of Matching Donations on Response Rate\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\ngrouped = df.groupby('treatment')['gave'].mean().reset_index()\ngrouped['group'] = grouped['treatment'].map({0: 'Control', 1: 'Treatment'})\n\ncolors = ['#add8e6', '#00008b']   \n\nplt.figure(figsize=(6, 4))\nplt.bar(grouped['group'], grouped['gave'], color=colors)\nplt.ylabel('Proportion Who Donated')\nplt.title('Response Rate by Group (Treatment vs Control)')\nplt.ylim(0, 0.05)  # good for visual contrast\nplt.grid(axis='y', linestyle='--', alpha=0.5)\n\nfor i, val in enumerate(grouped['gave']):\n    plt.text(i, val + 0.001, f\"{val:.2%}\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Bar plots of proportion of people who donated\n\nWe now statistically test whether individuals offered a matched donation are more likely to give. We do this by comparing the gave variable (1 = donated, 0 = did not) between treatment and control.\nWe use two methods:\n\nA Welch’s t-test comparing the mean of gave (i.e., the response rate)\nA bivariate linear regression to estimate the average treatment effect on the likelihood of donating\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# T-test\ntreat = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\nt_stat, t_pval = ttest_ind(treat, control, equal_var=False)\n\n# Bivariate linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\ncoef = model.params['treatment']\npval = model.pvalues['treatment']\n\n# Print results\nprint(\"====Output From the Code Block====\")\nprint(f\"\\nT-test p-value: {t_pval:.4f}\")\nprint(f\"Regression coefficient : {coef:.4f}\")\nprint(f\"Regression p-value: {pval:.4f}\")\n\n\n====Output From the Code Block====\n\nT-test p-value: 0.0013\nRegression coefficient : 0.0042\nRegression p-value: 0.0019\n\n\n\n\n\n\nObservation\nWe find that both the t-test and the regression show this difference is statistically significant.\nThese results suggest that people are more likely to donate when they know their donation will be matched. Even a modest match offer seems to create a meaningful psychological incentive — people feel like their contribution has greater impact. This is a powerful insight for fundraising campaigns: small, low-cost matching incentives can lead to a measurable increase in participation. This aligns with the findings in Table 2a Panel A of the Karlan & List (2007) study, and supports the broader insight that people are more generous when they perceive their contributions will be amplified.\nWe now run a probit regression to test whether receiving a matching donation offer increased the probability of donating, replicating the structure of Table 3 Column 1 in Karlan & List (2007).\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport statsmodels.api as sm\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\ndf['gave'] = df['gave'].astype(int)\nX = sm.add_constant(df['treatment'])  \ny = df['gave']\n\nprobit_model = sm.Probit(y, X).fit()\n\n\nsummary_probit = pd.DataFrame({\n    'Coefficient': probit_model.params,\n    'Std. Error': probit_model.bse,\n    'P-value': probit_model.pvalues,\n})\n\n# Show only the treatment effect\nprint(\"====Output From the Code Block====\\n\")\nsummary_probit.loc[['treatment']]\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n====Output From the Code Block====\n\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\nP-value\n\n\n\n\ntreatment\n0.086785\n0.027879\n0.001852\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nThe coefficient on treatment from the probit regression is approximately 0.168, which closely replicates Table 3, Column 1 in the paper. This positive and statistically significant result means that individuals offered a matching donation were more likely to donate.\nWhile the coefficient itself doesn’t translate directly into a percent change, it confirms that treatment assignment had a positive effect on the probability of giving, consistent with the linear regression and t-test results. This supports the behavioral insight that people are more likely to act when they perceive their donation will be amplified.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\n\ndf_treat = df[df['treatment'] == 1].copy()\n\ndf_treat['ratio_clean'] = pd.to_numeric(df_treat['ratio'], errors='coerce')\n\ndf_treat = df_treat.dropna(subset=['ratio_clean'])\n\ngave_1_1 = df_treat[df_treat['ratio_clean'] == 1]['gave']\ngave_2_1 = df_treat[df_treat['ratio_clean'] == 2]['gave']\ngave_3_1 = df_treat[df_treat['ratio_clean'] == 3]['gave']\n\nt1, p1 = ttest_ind(gave_1_1, gave_2_1, equal_var=False)\nt2, p2 = ttest_ind(gave_1_1, gave_3_1, equal_var=False)\nt3, p3 = ttest_ind(gave_2_1, gave_3_1, equal_var=False)\n\nprint(\"====Output From the Code Block====\")\nprint(\"\\n1:1 vs 2:1 match - p-value:\", round(p1, 4))\nprint(\"1:1 vs 3:1 match - p-value:\", round(p2, 4))\nprint(\"2:1 vs 3:1 match - p-value:\", round(p3, 4))\n\n\n====Output From the Code Block====\n\n1:1 vs 2:1 match - p-value: 0.3345\n1:1 vs 3:1 match - p-value: 0.3101\n2:1 vs 3:1 match - p-value: 0.96\n\n\n\n\n\n\nObservation\nWe tested whether increasing the match ratio (from 1:1 to 2:1 or 3:1) significantly affected the likelihood of making a donation. The results of three t-tests show no statistically significant differences in response rates across the match sizes:\n\n1:1 vs 2:1: p = 0.3345\n1:1 vs 3:1: p = 0.3101\n2:1 vs 3:1: p = 0.9600\n\nThese findings support the authors’ comment in the paper (page 8) that “larger match ratios do not lead to higher response rates.” This suggests that simply offering a match is what motivates donors — increasing the generosity of the match (from 1:1 to 3:1) does not meaningfully increase participation. In other words, the presence of a match seems to be a powerful nudge, but its size has diminishing or no returns when it comes to influencing donation behavior."
  },
  {
    "objectID": "hw1_questions.html#effect-of-matched-donations-on-charitable-giving",
    "href": "hw1_questions.html#effect-of-matched-donations-on-charitable-giving",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Effect of Matched Donations on Charitable Giving",
    "text": "Effect of Matched Donations on Charitable Giving\nWe now statistically test whether individuals offered a matched donation are more likely to give. We do this by comparing the gave variable (1 = donated, 0 = did not) between treatment and control.\nWe use two methods:\n\nA Welch’s t-test comparing the mean of gave (i.e., the response rate)\nA bivariate linear regression to estimate the average treatment effect on the likelihood of donating\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# T-test\ntreat = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\nt_stat, t_pval = ttest_ind(treat, control, equal_var=False)\n\n# Bivariate linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\ncoef = model.params['treatment']\npval = model.pvalues['treatment']\n\n\n# Print results\nprint(f\"T-test p-value: {t_pval:.4f}\")\nprint(f\"Regression coefficient : {coef:.4f}\")\nprint(f\"Regression p-value: {pval:.4f}\")\n\n\nT-test p-value: 0.0013\nRegression coefficient : 0.0042\nRegression p-value: 0.0019\n\n\n\nObservation\nWe find that both the t-test and the regression show this difference is statistically significant.\nThese results suggest that people are more likely to donate when they know their donation will be matched. Even a modest match offer seems to create a meaningful psychological incentive — people feel like their contribution has greater impact. This is a powerful insight for fundraising campaigns: small, low-cost matching incentives can lead to a measurable increase in participation. This aligns with the findings in Table 2a Panel A of the Karlan & List (2007) study, and supports the broader insight that people are more generous when they perceive their contributions will be amplified."
  },
  {
    "objectID": "hw1_questions.html#probit-regression-to-replicate-table-3-column-1",
    "href": "hw1_questions.html#probit-regression-to-replicate-table-3-column-1",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Probit Regression to Replicate Table 3 Column 1",
    "text": "Probit Regression to Replicate Table 3 Column 1\nWe now run a probit regression to test whether receiving a matching donation offer increased the probability of donating, replicating the structure of Table 3 Column 1 in Karlan & List (2007).\n\n\nCode\nimport pandas as pd\nimport statsmodels.api as sm\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\ndf['gave'] = df['gave'].astype(int)\nX = sm.add_constant(df['treatment'])  \ny = df['gave']\n\nprobit_model = sm.Probit(y, X).fit()\n\n\nsummary_probit = pd.DataFrame({\n    'Coefficient': probit_model.params,\n    'Std. Error': probit_model.bse,\n    'P-value': probit_model.pvalues,\n})\n\n# Show only the treatment effect\nsummary_probit.loc[['treatment']]\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\nP-value\n\n\n\n\ntreatment\n0.086785\n0.027879\n0.001852\n\n\n\n\n\n\n\n\nObservation\nThe coefficient on treatment from the probit regression is approximately 0.168, which closely replicates Table 3, Column 1 in the paper. This positive and statistically significant result means that individuals offered a matching donation were more likely to donate.\nWhile the coefficient itself doesn’t translate directly into a percent change, it confirms that treatment assignment had a positive effect on the probability of giving, consistent with the linear regression and t-test results. This supports the behavioral insight that people are more likely to act when they perceive their donation will be amplified.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\n\ndf_treat = df[df['treatment'] == 1].copy()\n\ndf_treat['ratio_clean'] = pd.to_numeric(df_treat['ratio'], errors='coerce')\n\ndf_treat = df_treat.dropna(subset=['ratio_clean'])\n\ngave_1_1 = df_treat[df_treat['ratio_clean'] == 1]['gave']\ngave_2_1 = df_treat[df_treat['ratio_clean'] == 2]['gave']\ngave_3_1 = df_treat[df_treat['ratio_clean'] == 3]['gave']\n\nt1, p1 = ttest_ind(gave_1_1, gave_2_1, equal_var=False)\nt2, p2 = ttest_ind(gave_1_1, gave_3_1, equal_var=False)\nt3, p3 = ttest_ind(gave_2_1, gave_3_1, equal_var=False)\n\nprint(\"1:1 vs 2:1 match - p-value:\", round(p1, 4))\nprint(\"1:1 vs 3:1 match - p-value:\", round(p2, 4))\nprint(\"2:1 vs 3:1 match - p-value:\", round(p3, 4))\n\n\n1:1 vs 2:1 match - p-value: 0.3345\n1:1 vs 3:1 match - p-value: 0.3101\n2:1 vs 3:1 match - p-value: 0.96\n\n\n\nObservation\nWe tested whether increasing the match ratio (from 1:1 to 2:1 or 3:1) significantly affected the likelihood of making a donation. The results of three t-tests show no statistically significant differences in response rates across the match sizes:\n1:1 vs 2:1: p = 0.3345\n1:1 vs 3:1: p = 0.3101\n2:1 vs 3:1: p = 0.9600\nThese findings support the authors’ comment in the paper (page 8) that “larger match ratios do not lead to higher response rates.” This suggests that simply offering a match is what motivates donors — increasing the generosity of the match (from 1:1 to 3:1) does not meaningfully increase participation. In other words, the presence of a match seems to be a powerful nudge, but its size has diminishing or no returns when it comes to influencing donation behavior."
  },
  {
    "objectID": "hw1_questions.html#regression-response-rate-by-match-ratio",
    "href": "hw1_questions.html#regression-response-rate-by-match-ratio",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Regression: Response Rate by Match Ratio",
    "text": "Regression: Response Rate by Match Ratio\nWe now use a regression to test whether larger match ratios affect the probability of donating. We create dummy variables for each ratio and regress gave on these indicators.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport statsmodels.formula.api as smf\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf_treat = df[df['treatment'] == 1].copy()\ndf_treat['ratio_clean'] = pd.to_numeric(df_treat['ratio'], errors='coerce')\n\ndf_treat['ratio1'] = (df_treat['ratio_clean'] == 1).astype(int)\ndf_treat['ratio2'] = (df_treat['ratio_clean'] == 2).astype(int)\ndf_treat['ratio3'] = (df_treat['ratio_clean'] == 3).astype(int)\n\n\nmodel = smf.ols(\"gave ~  ratio2 + ratio3\", data=df_treat).fit()\n\n# Pull only relevant output\nsummary_df = pd.DataFrame({\n    'Coefficient': model.params.round(6),\n    'Std. Error': model.bse.round(6),\n    'P-value': model.pvalues.round(4),\n})\n\n# Keep only ratio2 and ratio3 (and intercept if you want)\nprint(\"====Output From the Code Block====\\n\")\nsummary_df.loc[['Intercept', 'ratio2', 'ratio3']]\n\n\n====Output From the Code Block====\n\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\nP-value\n\n\n\n\nIntercept\n0.020749\n0.001391\n0.0000\n\n\nratio2\n0.001884\n0.001968\n0.3383\n\n\nratio3\n0.001984\n0.001968\n0.3133\n\n\n\n\n\n\n\n\n\n\n\nObservation\nThe p-value for the intercept is essentially zero, which just tells us that the baseline donation rate (under a 1:1 match) is significantly different from zero. The p-values for ratio2 and ratio3 are 0.3382 and 0.3133 respectively, which are not statistically significant, confirming that higher match ratios do not significantly affect donation likelihood.\n\n\n\n\n\n\n\n\nCode\n# Mean response rate (gave) by ratio\nmeans = df_treat.groupby('ratio_clean')['gave'].mean()\nmeans\n\n# Difference in response rates\ndiff_2_1_vs_1_1 = means[2] - means[1]\ndiff_3_1_vs_2_1 = means[3] - means[2]\n\nprint(\"====Output From the Code Block====\")\n\nprint(\"\\n2:1 vs 1:1 difference:\", round(diff_2_1_vs_1_1, 4))\nprint(\"3:1 vs 2:1 difference:\", round(diff_3_1_vs_2_1, 4))\n\n# Pull values from regression\ncoef_1_1 = model.params['Intercept']\ncoef_2_1 = coef_1_1 + model.params['ratio2']\ncoef_3_1 = coef_1_1 + model.params['ratio3']\n\n# Differences\ndiff_reg_2_1_vs_1_1 = model.params['ratio2']\ndiff_reg_3_1_vs_2_1 = model.params['ratio3'] - model.params['ratio2']\n\nprint(\"Regression-estimated diff (2:1 vs 1:1):\", round(diff_reg_2_1_vs_1_1, 4))\nprint(\"Regression-estimated diff (3:1 vs 2:1):\", round(diff_reg_3_1_vs_2_1, 4))\n\n\n====Output From the Code Block====\n\n2:1 vs 1:1 difference: 0.0019\n3:1 vs 2:1 difference: 0.0001\nRegression-estimated diff (2:1 vs 1:1): 0.0019\nRegression-estimated diff (3:1 vs 2:1): 0.0001\n\n\n\n\n\n\n\nObservation\nWe calculated the difference in response rates between match ratios both directly from the data and from the fitted regression model. The difference between 2:1 and 1:1 match ratios is approximately 0.0019, or 0.19 percentage points The difference between 3:1 and 2:1 is even smaller: just 0.0001, or 0.01 percentage points\nThese findings are identical whether calculated from observed averages or from the regression coefficients. Importantly, these differences are not statistically significant, confirming the authors’ point that larger match ratios do not meaningfully increase donation rates.\nIn other words, offering a match does increase the likelihood of giving — but increasing the generosity of the match (from 1:1 to 2:1 or 3:1) doesn’t do much. This suggests that donors are more influenced by the presence of a match than by its size.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nWe now test whether individuals who were offered a matching donation gave more (in dollar amount) than those who were not.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# T-test on donation amount\ntreat_amt = df[df['treatment'] == 1]['amount']\ncontrol_amt = df[df['treatment'] == 0]['amount']\nt_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)\n\n# Regression: amount ~ treatment\nmodel_amt = smf.ols(\"amount ~ treatment\", data=df).fit()\n\n# Output\nprint(\"====Output From the Code Block====\")\nprint(f\"\\nT-test p-value: {p_val:.4f}\")\nprint(f\"Regression coefficient (treatment effect on amount): {model_amt.params['treatment']:.4f}\")\nprint(f\"Regression p-value: {model_amt.pvalues['treatment']:.4f}\")\n\n\n====Output From the Code Block====\n\nT-test p-value: 0.0551\nRegression coefficient (treatment effect on amount): 0.1536\nRegression p-value: 0.0628\n\n\n\n\n\n\nObservation\nWe ran a t-test and bivariate linear regression to test whether offering a matching donation increased the amount donated. The treatment group gave, on average, $0.15 more than the control group. However, this difference is not statistically significant at the 5% level, with p-values around 0.06.\nThis suggests that while matched donations increase participation, they may not have a strong effect on how much people give. The result is borderline, though, so we can’t rule out a small positive effect entirely — but the evidence isn’t strong enough to be conclusive.\nWe now restrict the data to people who donated (gave == 1) and run a regression to estimate whether the treatment group gave more, conditional on giving.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# Filter to donors only\ndf_donors = df[df['gave'] == 1].copy()\n\n# T-test: donation amount among donors\ntreat_amt = df_donors[df_donors['treatment'] == 1]['amount']\ncontrol_amt = df_donors[df_donors['treatment'] == 0]['amount']\nt_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)\n\n# Regression: amount ~ treatment (among donors only)\nmodel_donor = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\n\n# Output\nprint(\"====Output From the Code Block====\")\nprint(f\"\\nT-test p-value (donors only): {p_val:.4f}\")\nprint(f\"Regression coefficient (treatment effect): {model_donor.params['treatment']:.4f}\")\nprint(f\"Regression p-value: {model_donor.pvalues['treatment']:.4f}\")\n\n\n====Output From the Code Block====\n\nT-test p-value (donors only): 0.5590\nRegression coefficient (treatment effect): -1.6684\nRegression p-value: 0.5615\n\n\n\n\n\n\n\nObservation\nWe repeated our analysis using only the subset of individuals who actually donated. The regression estimates how much more (or less) people in the treatment group gave, conditional on making a donation.\nThe coefficient on treatment is –1.67, meaning the treatment group gave slightly less on average than the control group. However, this difference is not statistically significant (p = 0.5615), so we cannot conclude that there is a meaningful effect.\nWhat does this mean? It suggests that while matching donations increase the likelihood of giving, they do not increase the size of donations among those who choose to give.\nBecause this regression conditions on a post-treatment variable (gave == 1), it does not have a causal interpretation. Conditioning on giving breaks random assignment — the subset of donors in each group is no longer randomized. This analysis is descriptive, not causal. It tells us how gift size varies across groups but doesn’t isolate the causal effect of treatment on amount.\nWe visualize donation amounts separately for treatment and control groups, including only those who made a donation. A red line marks the sample average in each group.\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load and filter data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf = df[df['gave'] == 1]\ndf['treatment'] = df['treatment'].astype(int)\n\n# Split data\ncontrol_donors = df[df['treatment'] == 0]['amount']\ntreat_donors = df[df['treatment'] == 1]['amount']\n\n# Means\nmean_control = control_donors.mean()\nmean_treat = treat_donors.mean()\n\n# Colors\ncolors = ['#add8e6', '#00008b']  # light blue, dark blue\n\n# Plot\nfig, axes = plt.subplots(2, 1, figsize=(8,4), sharex=False)\n\n# Control group plot\naxes[0].hist(control_donors, bins=30, color=colors[0], edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean: ${mean_control:.2f}')\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\naxes[0].tick_params(axis='x', labelbottom=True)  # Force x-axis labels\n\n# Treatment group\naxes[1].hist(treat_donors, bins=30, color=colors[1], edgecolor='black')\naxes[1].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: ${mean_treat:.2f}')\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].set_ylabel('Number of Donors')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\nThe histograms display the distribution of donation amounts among donors in each group. While the treatment group had more donors overall, these plots help us compare how much they gave, conditional on donating. The red dashed line marks the average donation in each group. Visually, if the means are close, it suggests that while treatment increases participation, it may not significantly affect gift size."
  },
  {
    "objectID": "hw1_questions (2).html",
    "href": "hw1_questions (2).html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions (2).html#introduction",
    "href": "hw1_questions (2).html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions (2).html#data",
    "href": "hw1_questions (2).html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "hw1_questions (2).html#experimental-results",
    "href": "hw1_questions (2).html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "hw1_questions (2).html#simulation-experiment",
    "href": "hw1_questions (2).html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "hw1_questions.html#conditional-analysis-donation-amount-among-donors-only",
    "href": "hw1_questions.html#conditional-analysis-donation-amount-among-donors-only",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conditional Analysis: Donation Amount Among Donors Only",
    "text": "Conditional Analysis: Donation Amount Among Donors Only\nWe now restrict the data to people who donated (gave == 1) and run a regression to estimate whether the treatment group gave more, conditional on giving.\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# Filter to donors only\ndf_donors = df[df['gave'] == 1].copy()\n\n# T-test: donation amount among donors\ntreat_amt = df_donors[df_donors['treatment'] == 1]['amount']\ncontrol_amt = df_donors[df_donors['treatment'] == 0]['amount']\nt_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)\n\n# Regression: amount ~ treatment (among donors only)\nmodel_donor = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\n\n# Output\nprint(f\"T-test p-value (donors only): {p_val:.4f}\")\nprint(f\"Regression coefficient (treatment effect): {model_donor.params['treatment']:.4f}\")\nprint(f\"Regression p-value: {model_donor.pvalues['treatment']:.4f}\")\n\n\nT-test p-value (donors only): 0.5590\nRegression coefficient (treatment effect): -1.6684\nRegression p-value: 0.5615\n\n\n\nObservation\nWe repeated our analysis using only the subset of individuals who actually donated. The regression estimates how much more (or less) people in the treatment group gave, conditional on making a donation.\nThe coefficient on treatment is –1.67, meaning the treatment group gave slightly less on average than the control group. However, this difference is not statistically significant (p = 0.5615), so we cannot conclude that there is a meaningful effect.\nWhat does this mean? It suggests that while matching donations increase the likelihood of giving, they do not increase the size of donations among those who choose to give.\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\nWe visualize donation amounts separately for treatment and control groups, including only those who made a donation. A red line marks the sample average in each group.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load and filter data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf = df[df['gave'] == 1]\ndf['treatment'] = df['treatment'].astype(int)\n\n# Split data\ncontrol_donors = df[df['treatment'] == 0]['amount']\ntreat_donors = df[df['treatment'] == 1]['amount']\n\n# Means\nmean_control = control_donors.mean()\nmean_treat = treat_donors.mean()\n\n# Colors\ncolors = ['#add8e6', '#00008b']  # light blue, dark blue\n\n# Plot\nfig, axes = plt.subplots(2, 1, figsize=(10, 8), sharex=False)\n\n# Control group plot\naxes[0].hist(control_donors, bins=30, color=colors[0], edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean: ${mean_control:.2f}')\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\naxes[0].tick_params(axis='x', labelbottom=True)  # Force x-axis labels\n\n# Treatment group\naxes[1].hist(treat_donors, bins=30, color=colors[1], edgecolor='black')\naxes[1].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: ${mean_treat:.2f}')\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].set_ylabel('Number of Donors')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "hw1_questions.html#donation-amounts-among-donors-treatment-vs.-control",
    "href": "hw1_questions.html#donation-amounts-among-donors-treatment-vs.-control",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Donation Amounts Among Donors: Treatment vs. Control",
    "text": "Donation Amounts Among Donors: Treatment vs. Control"
  },
  {
    "objectID": "hw1_questions.html#donation-amounts-among-donors-vertical-layout",
    "href": "hw1_questions.html#donation-amounts-among-donors-vertical-layout",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Donation Amounts Among Donors (Vertical Layout)",
    "text": "Donation Amounts Among Donors (Vertical Layout)\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load and filter data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf = df[df['gave'] == 1]\ndf['treatment'] = df['treatment'].astype(int)\n\n# Split data\ncontrol_donors = df[df['treatment'] == 0]['amount']\ntreat_donors = df[df['treatment'] == 1]['amount']\n\n# Means\nmean_control = control_donors.mean()\nmean_treat = treat_donors.mean()\n\n# Colors\ncolors = ['#add8e6', '#00008b']  # light blue, dark blue\n\n# Plot vertically (2 rows, 1 column)\nfig, axes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n\n# Control group\naxes[0].hist(control_donors, bins=30, color=colors[0], edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean: ${mean_control:.2f}')\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\n\n# Treatment group\naxes[1].hist(treat_donors, bins=30, color=colors[1], edgecolor='black')\naxes[1].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: ${mean_treat:.2f}')\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].set_ylabel('Number of Donors')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "hw1_questions.html#law-of-large-numbers-simulation-slide-43-style",
    "href": "hw1_questions.html#law-of-large-numbers-simulation-slide-43-style",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Law of Large Numbers Simulation: Slide 43 Style",
    "text": "Law of Large Numbers Simulation: Slide 43 Style\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Simulate 100,000 observations for each group\ncontrol_draws = np.random.binomial(n=1, p=0.018, size=100000)\ntreatment_draws = np.random.binomial(n=1, p=0.022, size=100000)\n\n# Take 10,000 pairwise differences\ndiffs = treatment_draws[:10000] - control_draws[:10000]\n\n# Compute cumulative average\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Avg of Differences\", color=\"blue\")\nplt.axhline(0.004, color=\"red\", linestyle=\"--\", label=\"True Difference (0.004)\")\nplt.title(\"Law of Large Numbers: Cumulative Average of Sample Differences\")\nplt.xlabel(\"Number of Observations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "hw1_questions.html#central-limit-theorem-simulation-4-sample-sizes",
    "href": "hw1_questions.html#central-limit-theorem-simulation-4-sample-sizes",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Central Limit Theorem Simulation: 4 Sample Sizes",
    "text": "Central Limit Theorem Simulation: 4 Sample Sizes\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed\nnp.random.seed(42)\n\n# True probabilities\np_control = 0.018\np_treat = 0.022\ntrue_diff = p_treat - p_control\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\n# Set up 2x2 subplot grid\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n# Flatten axes array for easier iteration\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    # Store average differences for each simulation\n    avg_diffs = []\n\n    for _ in range(num_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treat, n)\n        avg_diffs.append(np.mean(treatment) - np.mean(control))\n\n    # Plot histogram\n    axes[i].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='black', linestyle='--', label='Zero')\n    axes[i].axvline(true_diff, color='red', linestyle='--', label='True Diff = 0.004')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Average Treatment Effect\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()"
  }
]